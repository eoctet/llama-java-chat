# ğŸ¤–ï¸ Llama Java Chat

[![CI](https://github.com/eoctet/llama-java-chat/actions/workflows/maven_build_deploy.yml/badge.svg)](https://github.com/eoctet/llama-java-chat/actions/workflows/maven_build_deploy.yml)
[![README English](https://img.shields.io/badge/Lang-English-blue)](./README.md)
[![Llama java core](https://img.shields.io/badge/Github-llama_java_core-green)](https://github.com/eoctet/llama-java-core.git)
![GitHub language count](https://img.shields.io/github/languages/count/eoctet/llama-java-chat)
[![GitHub](https://img.shields.io/github/license/eoctet/llama-java-core)](https://opensource.org/licenses/MIT)


è¿™æ˜¯ä¸€ä¸ª ğŸ¦™ `LlamaèŠå¤©æœºå™¨äººæœåŠ¡`ã€‚ä½ å¯ä»¥ç”¨å®ƒéƒ¨ç½²è‡ªå·±çš„ç§æœ‰æœåŠ¡ï¼Œæ”¯æŒ `Llama2` ç³»åˆ—æ¨¡å‹åŠå…¶ä»–å¼€æºæ¨¡å‹ã€‚

#### ä¸»è¦ç‰¹ç‚¹

- [X] ğŸš€ `OpenAPI`ï¼ˆéƒ¨åˆ†æ¨ç†å‚æ•°å·²æŒ‰ç…§Llama2è¿›è¡Œè°ƒæ•´ï¼‰
- [X] ğŸš€ è¿ç»­ç”Ÿæˆå’Œå¯¹è¯
- [X] ğŸš€ Web UIï¼Œä¾‹å¦‚ [`ChatGPT Next Web`](https://github.com/Yidadaa/ChatGPT-Next-Web)
- [X] ğŸš€ æœåŠ¡ç«¯éƒ¨ç½²
- [X] ğŸš€ å‘½ä»¤è¡Œäº¤äº’


## å¿«é€Ÿå¼€å§‹


#### ğŸ–¥ æœåŠ¡ç«¯éƒ¨ç½²

- ä¸‹è½½å¹¶å¯åŠ¨æœåŠ¡

```bash
# Default URL: http://YOUR_IP_ADDR:8152/

cd <YOUR_PATH>/chat-server & bash app_server.sh start
```

- ç›®å½•ç¤ºä¾‹

```text
=> chat-server
   âŒŠ___ chat-server.jar
   âŒŠ___ app_server.sh
   âŒŠ___ conf
        âŒŠ___ setting.json

Â·Â·Â·
```

ä¸ `ChatGPT` çš„æ¥å£è§„èŒƒä¿æŒä¸€è‡´ï¼Œä»…å®ç°ä¸»è¦çš„æ¥å£ï¼Œå¯ä»¥ä¸ [`ChatGPT Next Web`](https://github.com/Yidadaa/ChatGPT-Next-Web) ç­‰WebUIã€Appé›†æˆä½¿ç”¨ã€‚

> â„¹ï¸ __å…¶ä¸­ä¸åŒä¹‹å¤„__
> 1. æ–°å¢äº†Llamaç³»åˆ—æ¨¡å‹çš„å‚æ•°ï¼Œåˆ é™¤äº†ä¸æ”¯æŒçš„GPTå‚æ•°ï¼›
> 2. é»˜è®¤ä½¿ç”¨äº† `Llama2-chat` æç¤ºè¯æ¨¡ç‰ˆï¼Œå¦‚éœ€é€‚é…å…¶ä»–æ¨¡å‹ï¼Œå¯è‡ªè¡Œè°ƒæ•´ï¼›
> 3. æ²¡æœ‰è¯·æ±‚è®¤è¯ã€ä½¿ç”¨é‡æŸ¥è¯¢ç­‰ä¸éœ€è¦çš„åŠŸèƒ½ï¼›
> 4. ä¼˜åŒ–å¯¹è¯èŠå¤©æ¥å£ï¼Œä¸éœ€è¦ä¼ é€’å†å²å¯¹è¯ä¸Šä¸‹æ–‡ï¼Œä»…å½“å‰å¯¹è¯å†…å®¹å³å¯ã€‚
>
> > å®Œæ•´çš„APIä¿¡æ¯è¯·å‚è€ƒ[`API æ–‡æ¡£`](docs/API.md)ã€‚

![webui.png](docs%2Fwebui.png)

ä¸¾ä¸ªæ —å­

> `POST` **/v1/chat/completions**

```shell
curl --location 'http://127.0.0.1:8152/v1/chat/completions' \
--header 'Content-Type: application/json' \
--data '{
    "messages": [
        {
            "role": "SYSTEM",
            "content": "<YOUR_PROMPT>"
        },
        {
            "role": "USER",
            "content": "Who are you?"
        }
    ],
    "user": "william",
    "verbose": true,
    "stream": true,
    "model": "Llama2-chat"
}'
```

æ¥å£å°†ä»¥æµçš„æ–¹å¼è¿”å›æ•°æ®ï¼š

```json
{
    "id": "octetchat-98fhd2dvj7",
    "model": "Llama2-chat",
    "created": 1695614393810,
    "choices": [
        {
            "index": 0,
            "delta": {
                "content": "ä½ å¥½"
            },
            "finish_reason": "NONE"
        }
    ]
}
```

#### ğŸ¤– å‘½ä»¤è¡Œäº¤äº’

è¿è¡Œå‘½ä»¤è¡Œäº¤äº’ï¼ŒæŒ‡å®šéœ€è¦åŠ è½½çš„è¯­è¨€æ¨¡å‹ã€‚

```bash
java -jar chat-console.jar --model llama2-chat --system 'YOUR_PROMPT'
```

```txt
... ...

User: ä½ æ˜¯è°
AI: ä½œä¸ºä¸€ä¸ª AIï¼Œæˆ‘ä¸çŸ¥é“æˆ‘æ˜¯è°ã€‚æˆ‘çš„è®¾è®¡è€…å’Œåˆ›å»ºè€…åˆ›é€ äº†æˆ‘ã€‚
ä½†æ˜¯ï¼Œæˆ‘æ˜¯ä¸€ä¸ªè™šæ‹ŸåŠ©æ‰‹ï¼Œæ—¨åœ¨æä¾›å¸®åŠ©å’Œå›ç­”é—®é¢˜ã€‚
```

> ä½¿ç”¨ `help` æŸ¥çœ‹æ›´å¤šå‚æ•°ï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š

```bash
java -jar chat-console.jar --help

usage: LLAMA-JAVA-CHAT v1.1.0
 -c,--completions               Use completions mode.
    --frequency-penalty <arg>   Repeat alpha frequency penalty (default:
                                0.0, 0.0 = disabled)
 -h,--help                      Show this help message and exit.
    --keep <arg>                Number of tokens to keep from the context.
 -m,--model <arg>               Load model name, default: llama2-chat.
    --max-new-tokens <arg>      Maximum new token generation size
                                (default: 0 unlimited).
    --mirostat <arg>            Enable Mirostat sampling, controlling
                                perplexity during text generation
                                (default: 0, 0 = disabled, 1 = Mirostat, 2
                                = Mirostat 2.0).
    --mirostat-ent <arg>        Set the Mirostat target entropy, parameter
                                tau (default: 5.0).
    --mirostat-lr <arg>         Set the Mirostat learning rate, parameter
                                eta (default: 0.1).
    --no-penalize-nl <arg>      Disable penalization for newline tokens
                                when applying the repeat penalty (default:
                                true).
    --presence-penalty <arg>    Repeat alpha presence penalty (default:
                                0.0, 0.0 = disabled)
    --repeat-penalty <arg>      Control the repetition of token sequences
                                in the generated text (default: 1.1).
    --system <arg>              Set a system prompt.
    --temperature <arg>         Adjust the randomness of the generated
                                text (default: 0.8).
    --tfs <arg>                 Enable tail free sampling with parameter z
                                (default: 1.0, 1.0 = disabled).
    --top-k <arg>               Top-k sampling (default: 40, 0 =
                                disabled).
    --top-p <arg>               Top-p sampling (default: 0.9).
    --typical <arg>             Enable typical sampling sampling with
                                parameter p (default: 1.0, 1.0 =
                                disabled).
    --verbose-prompt            Print the prompt before generating text.
```

#### âš™ï¸ ç¼–è¯‘ï¼ˆå¯é€‰ï¼‰

ä½¿ç”¨ `Maven` ç¼–è¯‘ï¼š

```bash
git clone https://github.com/eoctet/llama-java-chat.git

# Maven build
cd llama-java-chat

# Build app type: server / console
bash maven_build.sh server
```


> âš ï¸ __æ³¨æ„äº‹é¡¹__
> 
> æœ¬é¡¹ç›®ä¸åŒ…å«è¯­è¨€æ¨¡å‹ï¼Œè¯·è‡ªè¡Œè·å–æ‰€éœ€çš„æ¨¡å‹æ–‡ä»¶ã€‚

## é—®é¢˜åé¦ˆ

- å¦‚æœä½ æœ‰ä»»ä½•ç–‘é—®ï¼Œæ¬¢è¿åœ¨GitHub Issueä¸­æäº¤ã€‚

